{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "kerasplus",
      "language": "python",
      "name": "kerasplus"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Simple BERT Tokenizer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuzanadobes/DRLND-Project-Collaboration-and-Competition/blob/master/Simple_BERT_Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdmvtRVBStCl",
        "colab_type": "text"
      },
      "source": [
        "# BERT TOKANIZATION UTILITY\n",
        "\n",
        "# Summary \n",
        "This notebooks demonstrates the use of BERT model for sentimental analysis applied to Twitter texts.\n",
        "Sentiment analysis is focused around text-mining of the text according for the purpose of classifying \"opinions\" discovered in the text. For simplest sentiment classifications are positive and negative.\n",
        "\n",
        "# DATA \n",
        "Twitter data is analyzed.\n",
        "\n",
        "### Introduction to BERT\n",
        "\n",
        "Google’s BERT produces word representations that are dynamically represented by the words around them. \n",
        "BERT allows requires minimal fine-tuning and provide pretrained models that produce good results. BERT is used to extract features, namely word and sentence embedding vectors, from text data. These embeddings are useful for keyword/search expansion, semantic search and information retrieval. An example application is for matching a customer question against a set of already answered questions or searches against  or matching a search query against existing collections of searches.  The representations capture intent and contextual meaning, and more than just matching common keyword or phrases.\n",
        "\n",
        "The vectors are used as high-quality feature inputs to NLP models which require inputs in the form of vectors, which consit of numbers.  Features like parts of speech need to be transformed into numerical representations. In the past, words have been represented either as uniquely indexed values, or as in the case of Word2Vec neural word embeddings, they are fixed-length feature embeddings, where each word has a fixed representation regardless of the context within which the word appears.\n",
        "\n",
        "\n",
        "### Understanding BERT\n",
        "Deep contextualized word representations assigning word vectors to words in context - typically a sentence - instead of \n",
        "assigning a vector to each word type. BERT is one of the most popular and successful examples of these embeddings. \n",
        "The authors of BERT released several versions of BERT pretrained on massive amounts of data, including a multilingual \n",
        "version which supports 104 languages in a single model.\n",
        "\n",
        "### Summary of steps\n",
        "Because BERT is a pretrained model that expects input data in a specific format, we will need:\n",
        "\n",
        "- special tokens to mark the beginning ([CLS]) and separation/end of sentences ([SEP])\n",
        "- tokens that conforms with the fixed vocabulary used in BERT\n",
        "- token IDs from BERT’s tokenizer\n",
        "- mask IDs to indicate which elements in the sequence are tokens and which are padding elements\n",
        "- segment IDs used to distinguish different sentences\n",
        "- positional embeddings used to show token position within the sequence\n",
        "\n",
        "### Representation of word “embeddings”\n",
        "\n",
        "tokenizer.tokenize(\"Telekom is the best company to work \")\n",
        "['tel', '##ek', '##om', 'is', 'the', 'best', 'company', 'to', 'work']\n",
        "\n",
        "The original word(s) has been split into smaller subwords and characters. The two hash signs are the tokenizer’s way to denote that this subword or character is part of a larger word and preceded by another subword. \n",
        "The BERT tokenizer was created with a WordPiece model which creates a fixed-size vocabulary of individual characters, subwords, and words. Since the vocabulary limit size of our BERT tokenizer model is 30,000, the WordPiece model generated a vocabulary that contains all English characters plus the ~30,000 most common words and subwords found in the English language corpus the model is trained on. This vocabulary contains four things:\n",
        "\n",
        "- Whole words\n",
        "- Subwords occuring at the front of a word or in isolation \n",
        "- Subwords not at the front of a word, which are preceded by ‘##’ \n",
        "- Individual characters\n",
        "\n",
        "### Segmentation\n",
        "BERT is trained on and expects sentence pairs, using 1s and 0s to distinguish between the two sentences. That is, for each token in “tokenized_text,” we must specify which sentence it belongs to: sentence 0 (a series of 0s) or sentence 1 (a series of 1s). For our purposes, single-sentence inputs only require a series of 1s, so we will create a vector of 1s for each token in our input sentence.\n",
        "\n",
        "For processing two sentences, each word in the first sentence should be assigned, plus the ‘[SEP]’ token a 0, and all tokens of the second sentence a 1.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eafkn2DuStC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "import pandas as pd\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_vckSaRStDz",
        "colab_type": "code",
        "outputId": "9b20f904-d544-4c52-aab0-d652475fff37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "!pip install bert\n",
        "import bert"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert\n",
            "  Downloading https://files.pythonhosted.org/packages/e8/e6/55ed98ef52b168a38192da1aff7265c640f214009790220664ee3b4cb52a/bert-2.2.0.tar.gz\n",
            "Collecting erlastic\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/30/f40d99fe35c38c2e0415b1e746c89569f2483e64ef65d054b9f0f382f234/erlastic-2.0.0.tar.gz\n",
            "Building wheels for collected packages: bert, erlastic\n",
            "  Building wheel for bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert: filename=bert-2.2.0-cp36-none-any.whl size=3756 sha256=66f96051ab8962f553f0beef49f7b7db1fbf03fa183227a7e257417b7df9fa81\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/71/b7/941459453bd38e5d97a8c886361dee19325e9933c9cf88ad46\n",
            "  Building wheel for erlastic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for erlastic: filename=erlastic-2.0.0-cp36-none-any.whl size=6786 sha256=bbe75b6b22fc594d217aabe120db35bf12bf9b985d90f5e2034d166c5b038eae\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/62/46/93c713a5f061aeeb4f16eb6bf5ee798816e6ddda70faa78e69\n",
            "Successfully built bert erlastic\n",
            "Installing collected packages: erlastic, bert\n",
            "Successfully installed bert-2.2.0 erlastic-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6WKpYKOStEb",
        "colab_type": "text"
      },
      "source": [
        "### Data Preporcessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikq2IgrzStEn",
        "colab_type": "code",
        "outputId": "5d395fc0-78d3-419f-ad9f-8561d11d8a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "#cols = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
        "#data = pd.read_csv('training.csv', header = None, names = cols, encoding = 'latin')\n",
        "data = pd.read_csv('training.csv', header = None, encoding = 'latin')#\n",
        "dta.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b8a503bf67ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'latin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aKl2ty3StFf",
        "colab_type": "code",
        "outputId": "72668f41-ca68-48d2-eb2c-cf9351a0d0cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "data.drop(['id', 'date', 'query', 'user'], axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-33ff518baba4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'query'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3995\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3996\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3997\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3998\u001b[0m         )\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3934\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3935\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3936\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3970\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['id' 'date' 'query' 'user'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QshJdA1kStGC",
        "colab_type": "code",
        "outputId": "dc34e86d-e2a1-40e6-89e5-5bd5f0408596",
        "colab": {}
      },
      "source": [
        "data.sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    800000\n",
              "0    800000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGD_gSlCStGm",
        "colab_type": "code",
        "outputId": "43733aa3-d7fc-402a-db40-444346f5726d",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyjJ399kStHB",
        "colab_type": "text"
      },
      "source": [
        "Cleaning the tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V18oapjxStHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_tweets(tweet):\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\n",
        "    return tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H3EI3W2StH8",
        "colab_type": "code",
        "outputId": "13fd6445-27e6-40d0-ca3f-1acdd8e4031b",
        "colab": {}
      },
      "source": [
        "data_clean = [clean_tweets(tweet) for tweet in data.text]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\dobesz.Andreas-PC\\anaconda3\\envs\\kerasplus\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \" i just received my G8 viola exam.. and its... well... .. disappointing.. :\\..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
            "C:\\Users\\dobesz.Andreas-PC\\anaconda3\\envs\\kerasplus\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \"E3 ON PLAYSTATION HOME IN ABOUT AN HOUR!!!!!!!!!! \\../  \\../\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % self._decode_markup(markup)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irr5zkKQStIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_labels = data.sentiment.values\n",
        "data_labels[data_labels == 4] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_o8fs8bStJH",
        "colab_type": "code",
        "outputId": "94243cf7-32c9-44b5-dd08-4420cfd9e45f",
        "colab": {}
      },
      "source": [
        "data.sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    800000\n",
              "0    800000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_Scy2gxStJ3",
        "colab_type": "text"
      },
      "source": [
        "### BERT Keras layer \n",
        "\n",
        "Creating a BERT layer will provide access to meta data for tokenizer (ust like vocab size)\n",
        "\n",
        "We first create an object of the FullTokenizer class, and an BERT embedding layer from the BERT model from hub.KerasLayer. The trainable parameter is set to False, which means that we will not be training the BERT embedding. A BERT vocabulary file is created, as a numpy array. We then set the text to lowercase and finally we pass our vocabulary_file and to_lower_case variables to the BertTokenizer object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-khY43kStKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1'\n",
        "Tokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(bert_url, trainable= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_gYszzIStKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = Tokenizer(vocab_file, lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc5BnyWhStK_",
        "colab_type": "text"
      },
      "source": [
        "### Sensecheck for BERT tokenizer\n",
        "\n",
        "Map the token strings to their vocabulary indeces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8a3P7-kStLD",
        "colab_type": "code",
        "outputId": "236c07b9-16fa-4c53-8c1f-f95403ee7065",
        "colab": {}
      },
      "source": [
        "tokenizer.tokenize(\"Telekom is the best company to work \")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tel', '##ek', '##om', 'is', 'the', 'best', 'company', 'to', 'work']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc41K5M3StLp",
        "colab_type": "code",
        "outputId": "7b03e080-1f42-40bd-ac66-5eca7d06598b",
        "colab": {}
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"Telekom is the best company to work \"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10093, 5937, 5358, 2003, 1996, 2190, 2194, 2000, 2147]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4mf7igtStME",
        "colab_type": "text"
      },
      "source": [
        "### Tokenize the sample tweets data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I1mveaZStMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_sentence(sent):\n",
        "    return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzYcwYUzStMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_inputs = [encode_sentence(sent) for sent in data_clean]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py16zAKgStND",
        "colab_type": "text"
      },
      "source": [
        "### Data Creation\n",
        "\n",
        "Bert requires 3 different input for each sentence\n",
        "1. convert id to token\n",
        "2. padding token/ masking\n",
        "3. segment(0 indicate 1st sentence, 1 indicate token of second sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES8rGtzfStNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ids(token):\n",
        "    return tokenizer.convert_tokens_to_ids(token)\n",
        "\n",
        "def get_mask(token):\n",
        "    # this will return 1 if padding is not required  and 0 is padding is require\n",
        "    return np.char.not_equal(token, \"[PAD]\").astype(int) \n",
        "\n",
        "#identify if it is 1st sent or 2nd sentence\n",
        "def get_segments(token):\n",
        "    seg_ids=[]\n",
        "    current_seg_ids=0\n",
        "    for tok in token:\n",
        "        seg_ids.append(current_seg_ids)\n",
        "        if tok == '[SEP]':\n",
        "            current_seg_ids = 1-current_seg_ids\n",
        "    return seg_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2yiXEOmStNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_len = [[sent, data_labels[i], len(sent)] for i, sent in enumerate(data_inputs)]\n",
        "\n",
        "random.shuffle(data_len)\n",
        "data_len.sort(key=lambda x: x[2])\n",
        "\n",
        "#select only first 2 columns and where sentence_length is greater than 7\n",
        "sorted_all = [([get_ids(sent_lab[0]),\n",
        "               get_mask(sent_lab[0]),\n",
        "               get_segments(sent_lab[0])], sent_lab[1]) for sent_lab in data_len if sent_lab[2] > 7]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onjbnhFQStOx",
        "colab_type": "text"
      },
      "source": [
        "### Sensecheck\n",
        "\n",
        "This returns 2 tensors: \n",
        "    we use 1st tensor when we are doing any classification task, \n",
        "    and 2nd is used when we want token wise specification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJLWsHQtStO5",
        "colab_type": "code",
        "outputId": "810761d1-e5d3-4f05-d708-19d11ec8d455",
        "colab": {}
      },
      "source": [
        "my_sent = [\"[CLS]\"] + tokenizer.tokenize(\"Roses are red. Water is blue\") + [\"[SEP]\"]\n",
        "bert_layer([tf.expand_dims(tf.cast(get_ids(my_sent),tf.int32), 0), \n",
        "            tf.expand_dims(tf.cast(get_mask(my_sent),tf.int32), 0),\n",
        "            tf.expand_dims(tf.cast(get_segments(my_sent),tf.int32), 0)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              " array([[-0.8880781 , -0.49188244, -0.94932246,  0.8968192 ,  0.755771  ,\n",
              "         -0.22770368,  0.8709753 ,  0.33833498, -0.7908284 , -0.9999901 ,\n",
              "         -0.6133331 ,  0.9477908 ,  0.9889228 ,  0.53215766,  0.94513303,\n",
              "         -0.55921215, -0.2919084 , -0.6994527 ,  0.47294235, -0.43830714,\n",
              "          0.8081388 ,  0.9999961 , -0.303607  ,  0.28442976,  0.5896429 ,\n",
              "          0.9904285 , -0.7335669 ,  0.9400157 ,  0.96096396,  0.78111243,\n",
              "         -0.61328346,  0.28224257, -0.99593884, -0.19647846, -0.9765973 ,\n",
              "         -0.9966745 ,  0.51982385, -0.6446738 ,  0.01374471,  0.06916006,\n",
              "         -0.9207242 ,  0.4120631 ,  0.9999898 ,  0.22642383,  0.651158  ,\n",
              "         -0.29540482, -1.        ,  0.5123887 , -0.8712981 ,  0.92095476,\n",
              "          0.89726746,  0.89020276,  0.14599545,  0.55230975,  0.5531425 ,\n",
              "         -0.3581166 , -0.04199617,  0.3269583 , -0.27745858, -0.6523695 ,\n",
              "         -0.63723606,  0.54434645, -0.9406472 , -0.9209846 ,  0.92955023,\n",
              "          0.8073317 , -0.3667992 , -0.3891651 , -0.1037916 , -0.14509691,\n",
              "          0.84816885,  0.36574674, -0.025014  , -0.8717173 ,  0.69178444,\n",
              "          0.39272022, -0.5731751 ,  1.        , -0.3831023 , -0.98924506,\n",
              "          0.86162466,  0.72215   ,  0.56647384, -0.36651322,  0.30934614,\n",
              "         -1.        ,  0.55230963, -0.26378387, -0.9932012 ,  0.36360642,\n",
              "          0.5927176 , -0.29546264,  0.5389282 ,  0.53988594, -0.47153205,\n",
              "         -0.6646167 , -0.4165252 , -0.91803586, -0.4093074 , -0.609785  ,\n",
              "          0.18588525, -0.39987034, -0.3594632 , -0.40100944,  0.50106037,\n",
              "         -0.5303055 , -0.49495602,  0.36875677,  0.20147295,  0.73839134,\n",
              "          0.37897804, -0.43172833,  0.59271944, -0.9560506 ,  0.7069632 ,\n",
              "         -0.33781627, -0.98974407, -0.62827563, -0.9949444 ,  0.7483831 ,\n",
              "         -0.40386796, -0.316146  ,  0.9639325 , -0.52633655,  0.38685292,\n",
              "         -0.23596936, -0.9079976 , -1.        , -0.77582115, -0.7853493 ,\n",
              "          0.06470869, -0.4336128 , -0.9870199 , -0.9642313 ,  0.6515915 ,\n",
              "          0.95205307,  0.19733179,  0.99996907, -0.51145273,  0.958983  ,\n",
              "         -0.40669522, -0.8016897 ,  0.7779596 , -0.5532441 ,  0.8368566 ,\n",
              "          0.11799823, -0.6685002 ,  0.2712749 , -0.41365138,  0.6632068 ,\n",
              "         -0.7245954 , -0.3509811 , -0.83600867, -0.9486336 , -0.3897715 ,\n",
              "          0.95327437, -0.7463415 , -0.9454667 , -0.08186001, -0.29785386,\n",
              "         -0.5414847 ,  0.8561058 ,  0.7428219 ,  0.5097768 , -0.58214825,\n",
              "          0.5674932 ,  0.03191503,  0.71368647, -0.8243271 , -0.27521315,\n",
              "          0.5125027 , -0.40005496, -0.9122731 , -0.9882954 , -0.42316487,\n",
              "          0.49465534,  0.9940781 ,  0.7454186 ,  0.4228901 ,  0.80583096,\n",
              "         -0.34148058,  0.8285618 , -0.97661   ,  0.9887905 , -0.32595223,\n",
              "          0.37646237, -0.5851381 ,  0.24446048, -0.82805943,  0.31826773,\n",
              "          0.84595054, -0.8693359 , -0.778314  , -0.2146582 , -0.47929803,\n",
              "         -0.5198437 , -0.874379  ,  0.4736853 , -0.411876  , -0.5678655 ,\n",
              "         -0.15018982,  0.9231608 ,  0.95295006,  0.80570847,  0.41360337,\n",
              "          0.7522138 , -0.9144321 , -0.6023465 ,  0.19097123,  0.23929594,\n",
              "          0.28490508,  0.996607  , -0.8256259 , -0.22053134, -0.942926  ,\n",
              "         -0.9876571 ,  0.06663409, -0.9182575 , -0.29139116, -0.6916916 ,\n",
              "          0.7603008 , -0.45642364,  0.37232485,  0.51974446, -0.98187894,\n",
              "         -0.7933655 ,  0.4400814 , -0.5237333 ,  0.5107532 , -0.3148591 ,\n",
              "          0.8808443 ,  0.96453816, -0.6722387 ,  0.4528422 ,  0.9186161 ,\n",
              "         -0.91629744, -0.8128459 ,  0.83206165, -0.35528916,  0.7896317 ,\n",
              "         -0.7935857 ,  0.9922303 ,  0.9229421 ,  0.6757577 , -0.9454755 ,\n",
              "         -0.7715642 , -0.72199154, -0.6989377 , -0.1640892 , -0.05171279,\n",
              "          0.8873901 ,  0.567542  ,  0.4412074 ,  0.38988373, -0.77758414,\n",
              "          0.9943346 , -0.9208047 , -0.97703755, -0.8106085 , -0.34312937,\n",
              "         -0.9942179 ,  0.9206152 ,  0.38874978,  0.61636925, -0.62330216,\n",
              "         -0.6693633 , -0.97638726,  0.9010788 ,  0.2504387 ,  0.9821178 ,\n",
              "         -0.51527804, -0.9423854 , -0.7236108 , -0.95291066, -0.02672509,\n",
              "         -0.216869  , -0.45628577, -0.04609299, -0.9677454 ,  0.6395175 ,\n",
              "          0.6280847 ,  0.53257227, -0.82116973,  0.9988714 ,  1.        ,\n",
              "          0.9778791 ,  0.8875653 ,  0.8193516 , -0.9999662 , -0.7827525 ,\n",
              "          0.99999774, -0.99114954, -1.        , -0.9449164 , -0.7152755 ,\n",
              "          0.16961022, -1.        , -0.2534789 , -0.08063211, -0.9263529 ,\n",
              "          0.7378378 ,  0.97981757,  0.98949504, -1.        ,  0.86351454,\n",
              "          0.9338036 , -0.6826896 ,  0.94932306, -0.60514176,  0.9773665 ,\n",
              "          0.50261235,  0.5461937 , -0.2691511 ,  0.4319558 , -0.9571103 ,\n",
              "         -0.8806097 , -0.7380384 , -0.7837638 ,  0.99897987,  0.23501974,\n",
              "         -0.7899458 , -0.9341418 ,  0.71367776, -0.07225401,  0.09061378,\n",
              "         -0.96981966, -0.27683678,  0.7257589 ,  0.7988524 ,  0.24040085,\n",
              "          0.41607824, -0.67169386,  0.37393084,  0.00611452,  0.2902053 ,\n",
              "          0.6234062 , -0.95554155, -0.4079584 , -0.18994324,  0.29986134,\n",
              "         -0.7320985 , -0.96348155,  0.9646704 , -0.51894367,  0.94406414,\n",
              "          1.        ,  0.8495136 , -0.8931751 ,  0.5916277 ,  0.35426757,\n",
              "         -0.6385425 ,  1.        ,  0.8494205 , -0.988373  , -0.5600782 ,\n",
              "          0.7857872 , -0.6601587 , -0.7953897 ,  0.9996969 , -0.38182783,\n",
              "         -0.75080943, -0.53037953,  0.99144167, -0.99601865,  0.99688894,\n",
              "         -0.8451619 , -0.9839929 ,  0.9596187 ,  0.9566884 , -0.5845227 ,\n",
              "         -0.6987628 ,  0.28803968, -0.7241455 ,  0.38653657, -0.9313977 ,\n",
              "          0.7301341 ,  0.49292636, -0.19663149,  0.9232605 , -0.7641985 ,\n",
              "         -0.5015359 ,  0.32185927, -0.6596696 , -0.18519603,  0.9546715 ,\n",
              "          0.6883627 , -0.44173917, -0.07340494, -0.43172047, -0.8210003 ,\n",
              "         -0.96632195,  0.6719831 ,  1.        , -0.35263377,  0.8882279 ,\n",
              "         -0.4463129 , -0.06621864,  0.10171457,  0.53625077,  0.5761645 ,\n",
              "         -0.48369893, -0.84525913,  0.9250639 , -0.9463471 , -0.99502754,\n",
              "          0.8335003 ,  0.27728957, -0.26840132,  0.99999845,  0.6238539 ,\n",
              "          0.38731432,  0.3890529 ,  0.9774939 , -0.017186  ,  0.36666596,\n",
              "          0.8486703 ,  0.9912244 , -0.34436893,  0.61626154,  0.72875607,\n",
              "         -0.93006444, -0.4612231 , -0.689085  , -0.01175781, -0.96313864,\n",
              "          0.03207172, -0.9625194 ,  0.97976893,  0.95094997,  0.46415186,\n",
              "          0.33106202,  0.86564845,  1.        , -0.9044678 ,  0.54186773,\n",
              "          0.0398601 ,  0.83981925, -0.9999069 , -0.78659827, -0.4625567 ,\n",
              "         -0.17211035, -0.85122377, -0.38675126,  0.3242049 , -0.97374976,\n",
              "          0.83165896,  0.8667091 , -0.9872652 , -0.9939088 , -0.5968441 ,\n",
              "          0.67734873,  0.32051823, -0.99535286, -0.7215624 , -0.6966537 ,\n",
              "          0.8528161 , -0.47361967, -0.9525163 , -0.32798272, -0.4820439 ,\n",
              "          0.48092535, -0.37149143,  0.55428535,  0.8323961 ,  0.74180514,\n",
              "         -0.7381794 , -0.25716767, -0.17023864, -0.8027904 ,  0.8004163 ,\n",
              "         -0.79531217, -0.96476   , -0.2634873 ,  1.        , -0.61617315,\n",
              "          0.8728025 ,  0.7605102 ,  0.7156469 , -0.286276  ,  0.33191642,\n",
              "          0.95983493,  0.48725426, -0.71101564, -0.8696882 , -0.32261646,\n",
              "         -0.5936578 ,  0.6297823 ,  0.721834  ,  0.73789746,  0.8726117 ,\n",
              "          0.7350778 ,  0.21727538,  0.00241466, -0.03699747,  0.9993966 ,\n",
              "         -0.44293472, -0.22614107, -0.4524694 , -0.37161607, -0.4557165 ,\n",
              "          0.1419309 ,  1.        ,  0.34255078,  0.7645717 , -0.99554026,\n",
              "         -0.8956084 , -0.91138405,  1.        ,  0.86464304, -0.70656645,\n",
              "          0.7518504 ,  0.7547759 , -0.14464226,  0.66753507, -0.3680001 ,\n",
              "         -0.27741846,  0.44682136,  0.23997787,  0.96858394, -0.62699544,\n",
              "         -0.9806805 , -0.6069512 ,  0.5280437 , -0.96470547,  0.9999849 ,\n",
              "         -0.56555516, -0.42478552, -0.46940985, -0.4185357 , -0.03663494,\n",
              "          0.1007475 , -0.9829555 , -0.2365678 ,  0.22286284,  0.9743546 ,\n",
              "          0.35997817, -0.6346969 , -0.89149487,  0.86787134,  0.74558586,\n",
              "         -0.93448895, -0.96998394,  0.9778413 , -0.9817366 ,  0.70943725,\n",
              "          1.        ,  0.377232  ,  0.2216865 ,  0.24678111, -0.34478164,\n",
              "          0.3850064 , -0.7593556 ,  0.57650614, -0.9540889 , -0.4460699 ,\n",
              "         -0.23660587,  0.43670833, -0.23904712, -0.68224216,  0.78253925,\n",
              "          0.31058854, -0.5439588 , -0.70216465, -0.21084571,  0.49499118,\n",
              "          0.89635307, -0.3609786 , -0.24079043,  0.12598911, -0.0988397 ,\n",
              "         -0.94488615, -0.57172704, -0.6041    , -0.9999985 ,  0.490741  ,\n",
              "         -1.        ,  0.6680212 ,  0.22830284, -0.3158104 ,  0.9104533 ,\n",
              "          0.42973825,  0.791894  , -0.83044267, -0.8552688 ,  0.55385554,\n",
              "          0.84917337, -0.5080448 , -0.6715166 , -0.8147844 ,  0.41336623,\n",
              "         -0.05001746,  0.41040614, -0.76011604,  0.7426703 , -0.25950393,\n",
              "          1.        ,  0.0849425 , -0.60224414, -0.96389157,  0.28371757,\n",
              "         -0.37539187,  1.        , -0.7912105 , -0.97106314,  0.42612228,\n",
              "         -0.62597984, -0.88139296,  0.50422406,  0.05835281, -0.81203157,\n",
              "         -0.9519241 ,  0.9446641 ,  0.80924153, -0.6216848 ,  0.8143195 ,\n",
              "         -0.4058735 , -0.51180744,  0.19201653,  0.9162566 ,  0.99098414,\n",
              "          0.64496946,  0.88575584, -0.31808704, -0.623412  ,  0.9784542 ,\n",
              "          0.34352198,  0.3723187 ,  0.30985793,  1.        ,  0.4487462 ,\n",
              "         -0.92824775, -0.24327041, -0.97844666, -0.2520024 , -0.9431952 ,\n",
              "          0.42916533,  0.4451431 ,  0.9230808 , -0.29793668,  0.9750858 ,\n",
              "         -0.91682017,  0.11804875, -0.748458  , -0.5972147 ,  0.547169  ,\n",
              "         -0.9330167 , -0.9907969 , -0.9930653 ,  0.73185253, -0.52218604,\n",
              "         -0.09212952,  0.32749727,  0.24690233,  0.49682236,  0.547493  ,\n",
              "         -1.        ,  0.9547029 ,  0.5606818 ,  0.8876394 ,  0.97619265,\n",
              "          0.7344725 ,  0.7436325 ,  0.3490341 , -0.9895546 , -0.9693035 ,\n",
              "         -0.53446555, -0.36750895,  0.8476335 ,  0.835991  ,  0.89358854,\n",
              "          0.59471613, -0.5528699 , -0.21087605, -0.78494024, -0.8407283 ,\n",
              "         -0.99592084,  0.55011916, -0.613034  , -0.9142921 ,  0.9751337 ,\n",
              "         -0.32635817, -0.20302474, -0.2080969 , -0.8877448 ,  0.89081585,\n",
              "          0.7711589 ,  0.14147453,  0.18951432,  0.5557055 ,  0.9046457 ,\n",
              "          0.9334504 ,  0.9920425 , -0.8714197 ,  0.7329853 , -0.76347345,\n",
              "          0.5684796 ,  0.89655715, -0.9474258 ,  0.3309176 ,  0.60354143,\n",
              "         -0.63794756,  0.397261  , -0.3895725 , -0.9435325 ,  0.9316425 ,\n",
              "         -0.45297292,  0.58482057, -0.5588341 , -0.05465326, -0.43183511,\n",
              "         -0.38596106, -0.8002176 , -0.56746113,  0.58327967,  0.3155953 ,\n",
              "          0.89990073,  0.91196245, -0.04888805, -0.81139696, -0.32665592,\n",
              "         -0.73417735, -0.93813133,  0.89895004, -0.1518364 , -0.1221921 ,\n",
              "          0.68220466,  0.146715  ,  0.9699025 ,  0.3101111 , -0.43994763,\n",
              "         -0.3362409 , -0.75659096,  0.87052816, -0.6040997 , -0.6453248 ,\n",
              "         -0.72476983,  0.8322247 ,  0.4165354 ,  0.9999985 , -0.80930686,\n",
              "         -0.8940789 , -0.49234712, -0.4135176 ,  0.46816626, -0.71480095,\n",
              "         -1.        ,  0.5620953 , -0.5951974 ,  0.7994188 , -0.82734877,\n",
              "          0.7420363 , -0.74702066, -0.9824502 , -0.40535823,  0.3102609 ,\n",
              "          0.7310061 , -0.49744087, -0.817805  ,  0.5203573 , -0.68322164,\n",
              "          0.9812112 ,  0.88448983, -0.27321717,  0.37460795,  0.69610626,\n",
              "         -0.7382255 , -0.7805081 ,  0.93105316]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 9, 768), dtype=float32, numpy=\n",
              " array([[[-0.16326208, -0.11754873, -0.284795  , ..., -0.43633187,\n",
              "           0.28340787,  0.41330197],\n",
              "         [ 0.38649756,  0.3110899 ,  0.50865567, ..., -0.35389775,\n",
              "           0.42345586,  0.06419793],\n",
              "         [ 0.30331412,  0.06218091,  0.36193648, ..., -0.54727626,\n",
              "           0.47385383, -0.09878056],\n",
              "         ...,\n",
              "         [ 0.22234151, -0.29083538,  0.16499832, ..., -0.19052392,\n",
              "           0.21865427,  0.6125287 ],\n",
              "         [-0.12867105, -0.18549868,  0.2547966 , ..., -0.2762865 ,\n",
              "           0.05457588, -0.39326456],\n",
              "         [ 0.93567836,  0.04426692, -0.34348065, ...,  0.11796486,\n",
              "          -0.66388077, -0.32846978]]], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2zrVMeZStPQ",
        "colab_type": "text"
      },
      "source": [
        "### Generator\n",
        "\n",
        "As all of our sentences are in unequal length we cannot build our dataset using tensor. For this we will use the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXNMnLwhStPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all, output_types = (tf.int32, tf.int32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWUZal84StPv",
        "colab_type": "raw"
      },
      "source": [
        "# This code did not work - see next cell.\n",
        "BATCH_SIZE = 32\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=(None,()), padding_values=(0, 0))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3tyYRV_StPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Alternative version for parameters:\n",
        "# padded_shapes= tf.TensorShape(None,()) or ((None, ), ()) \n",
        "# padding_values= (0, 0) or (tf.constant(0), tf.constant(0))\n",
        "BATCH_SIZE = 32\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE,padded_shapes=((None, None),()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qNYSoOqStQS",
        "colab_type": "code",
        "outputId": "4376ebc9-affb-43c9-e0ce-e69ba8dd2d8c",
        "colab": {}
      },
      "source": [
        "len(list(all_batched))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45136"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlft24T0StQx",
        "colab_type": "code",
        "outputId": "97c95977-2171-4969-bf6d-f46308175e12",
        "colab": {}
      },
      "source": [
        "len(list(sorted_all))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1444341"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}